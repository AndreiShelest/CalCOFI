{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "from helpers import random_seed, target_feature, rename_cols_for_lgbm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data and dividing into x and y\n",
    "train = pd.read_csv('../data/post_fs_train.csv', index_col=0)\n",
    "train = rename_cols_for_lgbm(train)\n",
    "\n",
    "test = pd.read_csv('../data/post_fs_test.csv', index_col=0)\n",
    "test = rename_cols_for_lgbm(test)\n",
    "\n",
    "y_train = train[target_feature]\n",
    "y_test = test[target_feature]\n",
    "\n",
    "x_train = train.drop(target_feature, axis=1)\n",
    "x_test = test.drop(target_feature, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradinet Boosting using LightGBM library\n",
    "\n",
    "For this part we will tune hyperparameters on reduced datset based on 10 most relevannt features (mututal information score) and later we will train the model on full dataset given the discovered parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 features by mututal information\n",
    "data = pd.read_excel('../scores/mutual_info_score.xlsx', index_col=0)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting top 10 columns\n",
    "columns = list(data.index.values)[:10]\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can train the LGBM regression model on default parameters on full data set\n",
    "model = LGBMRegressor()\n",
    "default_params = model.get_params()\n",
    "print(pd.DataFrame.from_dict(default_params, orient='index'))\n",
    "scores = cross_val_score(model, x_train, y_train, scoring = 'neg_root_mean_squared_error', cv=5, verbose=1)\n",
    "print('RMSE:', (-np.mean(scores))**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE with default parameters for whole dataset is 0.344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning using randomised grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'n_estimators':[20, 40, 70, 100, 200, 80, 90],\n",
    "    'max_depth': [3, 4, 6, 8, 9, 10, 20],\n",
    "    'num_leaves': [5, 20, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.20, 0.03, 0.45, 0.85, 0.6, 0.75, 1],\n",
    "    'min_child_samples': list(range(20, 500, 10)),\n",
    "    'reg_alpha': [0.001, 0.0007, 0.1, 0.03, 0.06, 0.8, 0.65, 0.3, 1],\n",
    "    'reg_lambda': [0.01, 0.1, 1, 0.6, 0.006, 0.3, 0.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_grid = LGBMRegressor()\n",
    "if compute_cv:\n",
    "    lgbm_reg = RandomizedSearchCV(model_for_grid, params, scoring='neg_root_mean_squared_error', n_iter=18, random_state=random_seed)\n",
    "    lgbm_cv_fit = lgbm_reg.fit(x_train[columns], y_train)\n",
    "    parameters = lgbm_cv_fit.best_params_\n",
    "    score = lgbm_cv_fit.best_score_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters:', parameters)\n",
    "print('RMSE:', -score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that after tuning the parameters with grid search we improved slightly the model's performence.\n",
    "Now, let's see if that parameters also imporve the performence on model trained on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuned = LGBMRegressor(**parameters, verbose=1)\n",
    "model_tuned.fit(x_train.values, y_train)\n",
    "with open(\"../models/LGBM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_tuned, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_predict = model_tuned.predict(x_test)\n",
    "print('RMSE:',mean_squared_error(y_test, y_predict)**0.5)\n",
    "print('R2', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
