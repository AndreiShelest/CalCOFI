{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML project - CalCOFI dataset\n",
    "\n",
    "As explained in the README.md we are working CalCOFI dataset.\n",
    "\n",
    "The data and information about it can be found here : https://www.kaggle.com/datasets/sohier/calcofi/\n",
    "\n",
    "The description of the columns: https://new.data.calcofi.com/index.php/database/calcofi-database/bottle-field-descriptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with loading in the data and see what we haev there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helpers\n",
    "\n",
    "np.random.seed(helpers.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data folders\n",
    "bottle_data_path = '../data/bottle'\n",
    "cast_data_path = '../data/cast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in\n",
    "bottle_df = pd.read_csv(f'{bottle_data_path}/bottle.csv', encoding='UTF-8')\n",
    "cast_df = pd.read_csv(f'{cast_data_path}/cast.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploration of dataset\n",
    "As mentioned before, CalCOFI dataset contains two sets of data, one (bottle) with oceanographic data, and the other (cast) with sampling stations data and geolocation data. Let's look at the samples of each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will mostly deal with Bottle table due to it containing actual water quality data. \n",
    "\n",
    "Cast table, on the other hand, might be used if we would like to retrieve the geolocation of the measurements. So let's drop everything not related to the geolocation from Cast table and merge this with bottle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_df = cast_df[['Cst_Cnt', 'Lat_Dec', 'Lon_Dec']]\n",
    "\n",
    "df = pd.merge(bottle_df, cast_df, on='Cst_Cnt')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make plot of location of sampling stations (boats) from cast dataset, and we can clearly see the American west coast landline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_df.plot(kind=\"scatter\", x=\"Lon_Dec\", y=\"Lat_Dec\", grid=True, xlabel='Longitude', ylabel='Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset general info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_df_info = df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some variables have a lot of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size of a current dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What problem are we solving?\n",
    "\n",
    "The idea of the project will be to predict the temperature of water."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing excessive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RecInd column\n",
    "\n",
    "According to the description, this is a categorical column with values:\n",
    "\n",
    "**Record Indicator**\n",
    "* \"3\" - Observed Data\n",
    "* \"4\" - Educated office guess (ghost)\n",
    "* \"5\" - Data from STD or CTD device\n",
    "* \"6\" - Duplicate Depth\n",
    "* \"7\" - Interpolated to a standard depth\n",
    "\n",
    "In the context of the project, We suggest omitting interpolated data, as it is generally used to compare observations in different regions of the world, and for us actual observations have more value. Also, as it seems, \"Duplicate Depth\" means extra measurement taken, so, perhaps, we can omit it as well. Therefore, we'll keep only indicators \"3\" and \"5\", which comes with a drawback of reducing the amount of rows almoust by half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('RecInd').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_drop_idx = df.loc[(df['RecInd'] != 3) & (df['RecInd'] != 5)].index\n",
    "\n",
    "df.drop(index=bottle_drop_idx, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Reported\" columns\n",
    "\n",
    "Some columns have \"reported\" counterparts. Perhaps, they are highly correlated or even very close to each other, and we can remove even more columns. Let's calculate difference between a pair of columns divided by mean value of the reported column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reported_cols_pairs = [\n",
    "    ('Depthm', 'R_Depth'), \n",
    "    ('T_degC', 'R_TEMP'),\n",
    "    ('R_POTEMP', 'R_TEMP'), \n",
    "    ('Salnty', 'R_SALINITY'), \n",
    "    ('STheta', 'R_SIGMA'),\n",
    "    ('O2ml_L', 'R_O2'), \n",
    "    ('O2Sat', 'R_O2Sat'),\n",
    "    ('SiO3uM', 'R_SIO3'),\n",
    "    ('PO4uM', 'R_PO4'),\n",
    "    ('NO3uM', 'R_NO3'),\n",
    "    ('NO2uM', 'R_NO2'),\n",
    "    ('NH3uM', 'R_NH4'),\n",
    "    ('ChlorA', 'R_CHLA'),\n",
    "    ('Phaeop', 'R_PHAEO')\n",
    "]\n",
    "\n",
    "reported_diff_mean = pd.Series()\n",
    "\n",
    "for pair in reported_cols_pairs:\n",
    "    pair_key = f'{pair[0]}|{pair[1]}'\n",
    "    reported_diff_mean[pair_key] = np.nanmean(df[pair[0]] - df[pair[1]]) / np.nanmean(df[pair[1]])\n",
    "\n",
    "reported_diff_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the values are effectively negligible, hence we can keep only \"reported\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[c[0] for c in reported_cols_pairs], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Productivity\n",
    "\n",
    "Unfortunately, there is too little data about primary productivity measurements (the rate at which energy is converted to organic substances by photosynthetic producers), which could otherwise be very useful. Perhaps, it could be studied separately another time. CalCOFI uses radioactive carbon $C_{14}$ for primary productivity measurements (as far as I understand, carbon is injected in the ecosystem and then \"travels\" together with microorganisms), therefore we drop columns related to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_cols = ['C14As1', 'C14A1p', 'C14A1q', 'C14As2', 'C14A2p', 'C14A2q', 'DarkAs', 'DarkAp', 'DarkAq', 'MeanAs', 'MeanAp', 'MeanAq', 'IncTim', 'LightP']\n",
    "\n",
    "df.drop(columns=carbon_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision columns\n",
    "There are some measurement precision columns present in the dataset. We don't need them for the model construction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_cols = ['T_prec', 'S_prec']\n",
    "df.drop(columns=prec_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Codes columns\n",
    "\n",
    "According to https://new.data.calcofi.com/index.php/database/calcofi-database/bottle-field-descriptions, when we have quality code 0 or blank, it means that the sample has good quality. These are categorical columns.\n",
    "\n",
    "**Quality Code**\n",
    "\n",
    "* Blank - Data OK\n",
    "* \"4\" - Zeroed due to value below detection limit\n",
    "* \"6\" - Data taken from CTD device\n",
    "* \"8\" - Originator thinks value is suspect\n",
    "* \"9\" - Missing Data\n",
    "\n",
    "My plan here is to remove these columns completely, but first it would be useful to know whether the values in meaningful columns are not filled because they are below detection level or just missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_qual_pairs = [\n",
    "    ('R_TEMP', 'T_qual'),\n",
    "    ('R_SALINITY', 'S_qual'),\n",
    "    ('R_PRES', 'P_qual'),\n",
    "    ('R_O2', 'O_qual'),\n",
    "    ('R_SIGMA', 'SThtaq'),\n",
    "    ('R_O2Sat', 'O2Satq'),\n",
    "    ('R_CHLA', 'Chlqua'),\n",
    "    ('R_PHAEO', 'Phaqua'),\n",
    "    ('R_PO4', 'PO4q'),\n",
    "    ('R_SIO3', 'SiO3qu'),\n",
    "    ('R_NO2', 'NO2q'),\n",
    "    ('R_NO3', 'NO3q'),\n",
    "    ('R_NH4', 'NH3q')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (col, qual) in col_qual_pairs:\n",
    "    qual_values = df[[col, qual]].value_counts(qual)\n",
    "    print(qual_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each column with quality=8, we are replacing its value with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (col, qual) in col_qual_pairs:\n",
    "    df.loc[df[qual] == 8, col] = np.nan\n",
    "\n",
    "    print(df.loc[(df[qual] == 8) & df[col].notnull()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears, there are indeed a lot of missing values in columns, according to the authors of the dataset. We should consider it while imputing missing data. For now proceed to dropping quality columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_cols = df.filter(regex='.*_qual|.*qua|.*q').columns\n",
    "\n",
    "df.drop(columns=qual_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Descriptive\" and other data\n",
    "\n",
    "For the modelling purposes we do not need the columns like bottle count, different IDs etc., so we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "almost_empty_cols = ['Cst_Cnt', 'Btl_Cnt', 'Sta_ID', 'Depth_ID', 'BtlNum', 'RecInd', 'R_SAMP']\n",
    "\n",
    "df.drop(columns=almost_empty_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Almost empty columns\n",
    "\n",
    "Remove columns with little to no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "almost_empty_cols = ['DIC1', 'DIC2', 'TA1', 'TA2', 'pH2', 'pH1', 'DIC Quality Comment']\n",
    "\n",
    "df.drop(columns=almost_empty_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oxy_µmol/Kg\n",
    "\n",
    "This columns seems to have similar meaning to R_O2, just in different measurement units. Can we remove it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Oxy_µmol/Kg', 'R_O2']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are indeed completely correlated, therefore the answer is yes, we can drop Oxy_µmol/Kg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Oxy_µmol/Kg'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R_TEMP - target feature\n",
    "\n",
    "Since we decided to use R_TEMP column as a feature to probe against, imputing missing values is not a good strategy. Therefore we have to keep only the rows with R_TEMP present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[helpers.target_feature].isnull()].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data\n",
    "\n",
    "To conclude this part, we managed to greatly reduce the amount of features. Some of rows have also been removed due to their supposed syntheticity in the original dataset (interpolation). Now we can proceed to train/test split and to the exploratory data analysis to prepare the data for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'../data/dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calcofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
