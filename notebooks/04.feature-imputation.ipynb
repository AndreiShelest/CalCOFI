{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "random_seed = 2024\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_df = pd.read_csv(f'../data/barely_processed_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Imputation\n",
    "\n",
    "We see that most of the columns are missing at least some of the values, and most of them are missing a lot of values, like R_O2, R_O2Sat, R_SIO3, R_PO4, R_NO3, R_NO2, R_NH4, R_CHLA, R_PHAEO. Therefore feature imputation is required for the modelling.\n",
    "\n",
    "Let's try the multivariate feature imputation from scikit-learn.\n",
    "\n",
    "Also make sure that the values for most of the columns are non-negative, and coordinates are in appropriate ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values_for_imputation = {\n",
    "    'R_Depth': 0,\n",
    "    'R_TEMP': -np.inf,\n",
    "    'R_SALINITY': 0,\n",
    "    'R_SIGMA': 0,\n",
    "    'R_SVA': 0,\n",
    "    'R_DYNHT': 0,\n",
    "    'R_O2': 0, \n",
    "    'R_O2Sat': 0,\n",
    "    'R_SIO3': 0,\n",
    "    'R_PO4': 0,\n",
    "    'R_NO3': 0,\n",
    "    'R_NO2': 0,\n",
    "    'R_NH4': 0,\n",
    "    'R_CHLA': 0,\n",
    "    'R_PHAEO': 0,\n",
    "    'R_PRES': 0,\n",
    "    'Lat_Dec': -90,\n",
    "    'Lon_Dec': -180\n",
    "}\n",
    "\n",
    "max_values_for_imputation = {\n",
    "    'R_Depth': np.inf,\n",
    "    'R_TEMP': np.inf,\n",
    "    'R_SALINITY': np.inf,\n",
    "    'R_SIGMA': np.inf,\n",
    "    'R_SVA': np.inf,\n",
    "    'R_DYNHT': np.inf,\n",
    "    'R_O2': np.inf, \n",
    "    'R_O2Sat': np.inf,\n",
    "    'R_SIO3': np.inf,\n",
    "    'R_PO4': np.inf,\n",
    "    'R_NO3': np.inf,\n",
    "    'R_NO2': np.inf,\n",
    "    'R_NH4': np.inf,\n",
    "    'R_CHLA': np.inf,\n",
    "    'R_PHAEO': np.inf,\n",
    "    'R_PRES': np.inf,\n",
    "    'Lat_Dec': 90,\n",
    "    'Lon_Dec': 180\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(random_state=random_seed, min_value=list(min_values_for_imputation.values()), max_value=list(max_values_for_imputation.values()))\n",
    "\n",
    "imputed_train = imputer.fit_transform(initial_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(imputed_train, index = initial_train_df.index, columns = initial_train_df.columns)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values have been imputed. Let's analyze the resulting distributions of features after the imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=train_df.shape[1], ncols=2, figsize=(25, 45), layout='constrained')\n",
    "for col, ax in zip(train_df.columns, axes):\n",
    "    sns.histplot(initial_train_df[col], ax=ax[0], bins=50).set(title=f'Initial: {col}', xlabel=\"\")\n",
    "    sns.histplot(train_df[col], ax=ax[1], bins=50).set(title=f'Imputed: {col}', xlabel=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the shapes of the PDFs are mostly preserved, except for R_O2 and R_O2Sat, where a mean imputation is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=train_df.shape[1], ncols=2, figsize=(25, 45), layout='constrained')\n",
    "for col, ax in zip(train_df.columns, axes):\n",
    "    sns.scatterplot(x=initial_train_df[col], y=initial_train_df['R_SALINITY'], ax=ax[0]).set(title=f'Initial: {col}', xlabel=\"\")\n",
    "    sns.scatterplot(x=train_df[col], y=train_df['R_SALINITY'], ax=ax[1]).set(title=f'Imputed: {col}', xlabel=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "\n",
    "Apply the imputation algorithm trained on the train dataset to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test_df = pd.read_csv(f'../data/barely_processed_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_test = imputer.transform(initial_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(imputed_test, index = initial_test_df.index, columns = initial_test_df.columns)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distributions of test imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=test_df.shape[1], ncols=2, figsize=(25, 45), layout='constrained')\n",
    "for col, ax in zip(test_df.columns, axes):\n",
    "    sns.histplot(initial_test_df[col], ax=ax[0], bins=50).set(title=f'Initial: {col}', xlabel=\"\")\n",
    "    sns.histplot(test_df[col], ax=ax[1], bins=50).set(title=f'Imputed: {col}', xlabel=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imputation mostly preserves the shapes of the PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=test_df.shape[1], ncols=2, figsize=(25, 45), layout='constrained')\n",
    "for col, ax in zip(train_df.columns, axes):\n",
    "    sns.scatterplot(x=initial_test_df[col], y=initial_test_df['R_SALINITY'], ax=ax[0]).set(title=f'Initial: {col}', xlabel=\"\")\n",
    "    sns.scatterplot(x=test_df[col], y=test_df['R_SALINITY'], ax=ax[1]).set(title=f'Imputed: {col}', xlabel=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data\n",
    "\n",
    "Save the imputed datasets and the imputer model itself for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f'../data/post_impute_train.csv')\n",
    "test_df.to_csv(f'../data/post_impute_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(imputer, '../data/imputer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calcofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
